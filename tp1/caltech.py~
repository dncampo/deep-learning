import os, random, math, pandas
import numpy as np
from scipy import misc
import matplotlib.pyplot as plt
from loadImages import loadImages
from normalizeImages import normalizeImages
from scaleImage import scaleImage
from getPatches import getPatches
# borrar: cosas para sacar cuando este listo para presentar

dataDir='/home/leandro/workspace/Dropbox/ref/deeplearning_cifasis/data/caltech/'
# dataDir='/home/tc9/Escritorio/0_Copartida/Caltech101/'
imFiles=[]

for d in os.walk(dataDir):
    for f in d[2]:
        if ".directory" not in f:
            imFiles.append(d[0]+"/"+f)
            break # borrar: para hacer pruebas mas rapido

# TP1.1:
#Implemente una función para leer las imágenes de ​Caltech 101​ y para retornar una matriz de numpy. Debido a que las imágenes no son homogéneas, se plantean varias dificultades. Proponga un criterio uniforme para resolver estos problemas. 

# some dataset stats...
datasizes=np.zeros((len(imFiles),3))
for (k,f) in enumerate(imFiles):
    # tomar parametros de la base de datos
    im=misc.imread(f)
    datasizes[k,:]=(im.shape[0],im.shape[1],im.ndim)

    
imdata=pandas.DataFrame(datasizes)
#imdata.boxplot()
#plt.show()

# se puede ver la distribución. Se pueden tomar los cuartiles máximos como parametros para homogeneizar a imagenes de tamaño fijo RGB y descartar las imagenes muy grandes (para este punto del TP)


maxSize=(500,500)
print("Total: %d imágenes, %d en RGB\n" %(datasizes.shape[0],np.count_nonzero(datasizes[:,2]==3)))
print("Fijando el tamaño máximo quedan afuera %d imágenes\n" %(np.count_nonzero(datasizes[:,0]>maxSize[0])+np.count_nonzero(datasizes[:,1]>maxSize[1])))
imFiles=[f for (k,f) in enumerate(imFiles) if datasizes[k,0]<maxSize[0] if datasizes[k,1]<maxSize[1]]

imFiles=imFiles[1:10]# borrar: dejo algunas de prueba

images=loadImages(imFiles,maxSize)

# TP1.2:
#Implemente funciones de preprocesamiento para las imágenes de manera de extraer ventanas de tamaño 16x16 en posiciones aleatorias de la imágen, con el valor medio de las imágenes sobre cada canal sea 0 y la varianza 1. Describa el efecto sobre las imágenes procesadas. 

f,subplots=plt.subplots(2,2)
imej=[7,5]

for k  in [0,1]:
    subplots[k,0].imshow(images[imej[k]].copy())

for c in [0,1,2]:
    print('Image %d channel %d %f (STD: %f)' %(imej[0],c,np.mean(images[imej[0],:,:,c]),np.std(images[imej[0],:,:,c])))

#images=normalizeImages(images)

for c in [0,1,2]:
    print('Image 0 channel %d %f (STD: %f)' %(c,np.mean(images[imej[0],:,:,c]),np.std(images[imej[0],:,:,c])))

for k  in [0,1]:
    im2plot=scaleImage(images[imej[k]])
    subplots[k,1].imshow(im2plot)
#plt.show()

# básicamente el efecto es normalizar los canales para que tengan igual peso. Esto se puede ver como una "ecualización" de color en la imagen.

patches=getPatches(images,N=10,S=32)

f2,subplots=plt.subplots(2,5)
for k1  in range(0,2):
    for k2  in range(0,5):
        im2plot=scaleImage(patches[imej[0],k1*5+k2])
        subplots[k1,k2].imshow(im2plot)
plt.show()

 
# TP1.3:
# El objetivo del whitening es decorrelacionar variables. Los datos son transformados a un conjunto de variables donde la matriz de covarianza es la identidad. En cierta forma es similar a la transformación anterior, con la diferencia que aquella normaliza las varianzas y ésta elimina también las correlaciones entre variables.

# En el caso de las imágnes, si se ve el conjunto de píxeles como variabels (SxS en el caso de los parches), el whitening redefine los píxeles de forma que la imagen se ve como ruido blanco, pero la informacíón está ahi (no es evidente para el humano). El whitening reduce la redundancia (en las imagenes, pixeles contiguos tienen info similar). Dependiendo de la tecnica de aprendizaje maquinal, el witening puede ser necesario o no.


