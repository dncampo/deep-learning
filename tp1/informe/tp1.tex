\documentclass[11pt,spanish]{article}
\usepackage[spanish]{babel}
\selectlanguage{spanish}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}

\begin{document}

\title{Redes Neuronales Profundas: Trabajo Práctico 1}
\date{}
\maketitle

\section*{Respuestas}
El código realizado para la resolución de los ejercicios está disponible en \href{https://github.com/dncampo/deep-learning/tree/lpineda}{github} (branch \textit{lpineda})

\subsection*{Ejercicio 1}
Para leer el dataset completo se genera recursivamente una lista de \textit{strings} con las rutas de las imágenes. Luego, estas son leídas utilizando la función \textit{reshape\_image}, la cual descarta una fila o una columna si el alto o el ancho tienen dimensiones impares, y centra la imagen en un rectángulo negro de las medidas dadas.
Dado que el dataset completo no cabe en memoria (más de 50GB), solo se lee un subdirectorio.

\subsection*{Ejercicio 2}
En este ejercicio se toman imágenes directamente del dataset, sin el procesamiento realizado en el ejercicio 1. Dado que se deben extraer parches en posiciones aleatorias de la imagen, la subimagen podría ser seleccionada de uno de los bordes negros, lo cual no agregaría información relevante.

Por otro lado, para normalizar la imagen con $\mu=0$ y $\sigma^2=1$, a cada pixel de la imagen se le sustrae la media y se lo divide por la desviación estandar. Esto es, para una imagen $I$: 

\ \ 

\begin{center}
	\begin{math}
	\forall p_{i,j} \in I, \qquad (p_{i,j} - \mu_I) \div \sigma^2_I
	\end{math}
\end{center}

\ \

El resultado de este procesamiento se puede observar a continuación:

\begin{figure}[htbp]
	\centering
	\begin{minipage}[b]{0.35\textwidth}
		\includegraphics[width=\textwidth]{../image.jpg}
		\caption{Imagen original.}
		\label{img_original}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{0.35\textwidth}
		\includegraphics[width=\textwidth]{../normalized_image.jpg}
		\caption{$\mu=0 \quad \sigma^2=1$}
		\label{img_cuantizada}
	\end{minipage}
\end{figure}

La imagen transformada es inteligible puesto que al normalizar cada canal, los valores enteros de los pixeles en el rango $[0,255]$ son transformados a valores flotantes, y al tener una distribución de probabilidad con $\mu=0$ es de esperar la existencia de valores negativos. Estos nos son transformados correctamente por la librería utilizada\footnote{Python Imaging Library (PIL): http://www.pythonware.com/products/pil/}. \par
El hecho que la imagen sea inteligible no quiere decir que la información se halla perdido. Esto se puede comprobar al cuantizar los valores y transformarlos nuevamente al rango $[0,255]$ mediante la función:
\ \
\begin{center}
	\begin{math}
		f(x) = 255 \frac{x-min(I)}{max(I)-min(I)}
	\end{math}
\end{center}
donde nuevamente $I$ es una imagen dada. Esta función está implementada bajo el nombre \textit{quantize}, y el resultado de la transformación de la figura \ref{img_cuantizada} (en su versión de valores flotantes) puede observarse en la siguiente imagen:

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.35\textwidth]{../quantized_image.jpg}
\end{figure}	

\subsection*{Ejercicio 3}
Las imagenes naturales (las imagenes que los humanos estamos acostumbrados a ver, como paisajes, animales, etc) contienen información redundante dada la alta correlación entre pixeles adjacentes. Si utilizamos un dataset de imágenes para entrenar algún modelo, lo ideal sería que las entradas contengan la menor cantidad de información repetida posible; el objetivo de aplicar \textit{whitening} sobre cada imagen de un dataset es hacer que los datos con los que entrenamos la red neuronal no tengan información redundante. \par
Dados $m$ vectores de características $\mathbf{x}$ (nuestro dataset) con media cero $\mu_{\mathbf{x}_i}=0$, la matriz de covarianza está dada por:
\begin{center}
	\begin{math}
		\mathbf{\Sigma} = \frac{1}{m} \sum_{i=1}^{m} \mathbf{x} \mathbf{x}^T
	\end{math}
\end{center}

Si queremos que los datos no estén correlacionados, debemos transformar el dataset de forma que su matriz de covarianza $\mathbf{\Sigma}$ sea una matriz diagonal. Esta transformación se puede expresar lograrse pre-multiplicando cada vector de características por la matriz $\mathbf{\Phi}^T$, donde las columnas de $\mathbf{\Phi}$ son los eigenvectores de la matriz de covarianza $\mathbf{\Sigma}$. Podemos expresar la matriz de covarianza diagonalizada como:

\begin{center}
	\begin{math}
		\mathbf{\Phi}^T \mathbf{\Sigma} \mathbf{\Phi} = \mathbf{\Lambda}
	\end{math}
\end{center}
donde $\mathbf{\Lambda}$ es una matriz de ceros con los eigenvalores de la matriz de covarianza en su diagonal. Luego, la matriz de covarianza de $\mathbf{y} = \mathbf{\Phi}^T \mathbf{x}$ es la matriz diagonal $\mathbf{\Lambda}$. \par
Aplicar \textit{whitening} a un dato consiste en hacer que su matriz de covarianza tenga la forma $\mathbf{\Lambda} = \alpha \mathbf{I}$. Usando el hecho que:

\begin{center}
	\begin{math}
		\mathbf{\Lambda}\mathbf{\Lambda}^{-1} = 1 \rightarrow \mathbf{\Lambda}^{-1} = \mathbf{\Lambda}^{-1/2} \mathbf{I} \mathbf{\Lambda}^{-1/2} \rightarrow  \mathbf{I} = \mathbf{\Lambda}^{-1/2} \mathbf{\Lambda} \mathbf{\Lambda}^{-1/2}
	\end{math}
\end{center}

y reemplazando $\mathbf{\Lambda}$ tenemos que:

\begin{center}
	\begin{math}
	\mathbf{\Lambda}^{-1/2} \mathbf{\Phi}^T \mathbf{\Sigma} \mathbf{\Phi} \mathbf{\Lambda}^{-1/2} = \mathbf{I}
	\end{math}
\end{center}

Finalmente, la transformación $\mathbf{z}$ para \textit{blanquear} los datos esta dada por:
\begin{center}
	\begin{math}
	\mathbf{z} = \mathbf{\Lambda}^{-1/2} \mathbf{\Phi}^T \mathbf{\Sigma} \mathbf{x}
	\end{math}
\end{center}

Esto se puede comprobar al calcular la matriz de covarianza de $\mathbf{z}$
\begin{center}
	\begin{math}
		\mathbf{\Sigma} = \frac{1}{m} \sum_{i=1}^{m} \mathbf{z} \mathbf{z}^T = \
		\frac{1}{m} \sum_{i=1}^{m} \mathbf{\Lambda}^{-1/2} \mathbf{\Phi}^T \mathbf{x} \mathbf{x}^T  \mathbf{\Phi} \mathbf{\Lambda}^{-1/2} = \mathbf{I}
	\end{math}
\end{center}

\end{document}